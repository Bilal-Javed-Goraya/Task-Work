{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bbcb1d6e",
      "metadata": {
        "id": "bbcb1d6e"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D485ap6itC4",
        "outputId": "d293a094-b5e2-4f6f-b7cc-39bcefcc4516"
      },
      "id": "2D485ap6itC4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a0a2b567",
      "metadata": {
        "id": "a0a2b567"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fefcf6ac",
      "metadata": {
        "id": "fefcf6ac"
      },
      "source": [
        "# Let's load the original tsv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed07928",
      "metadata": {
        "scrolled": true,
        "id": "bed07928",
        "outputId": "e6a79715-789e-48f0-f283-d39099344c89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\232109533.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n",
            "Skipping line 20773: expected 15 fields, saw 22\n",
            "Skipping line 39834: expected 15 fields, saw 22\n",
            "Skipping line 52957: expected 15 fields, saw 22\n",
            "Skipping line 54540: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 80276: expected 15 fields, saw 22\n",
            "Skipping line 96168: expected 15 fields, saw 22\n",
            "Skipping line 96866: expected 15 fields, saw 22\n",
            "Skipping line 98175: expected 15 fields, saw 22\n",
            "Skipping line 112539: expected 15 fields, saw 22\n",
            "Skipping line 119377: expected 15 fields, saw 22\n",
            "Skipping line 120065: expected 15 fields, saw 22\n",
            "Skipping line 124703: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 134024: expected 15 fields, saw 22\n",
            "Skipping line 153938: expected 15 fields, saw 22\n",
            "Skipping line 156225: expected 15 fields, saw 22\n",
            "Skipping line 168603: expected 15 fields, saw 22\n",
            "Skipping line 187002: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 200397: expected 15 fields, saw 22\n",
            "Skipping line 203809: expected 15 fields, saw 22\n",
            "Skipping line 207680: expected 15 fields, saw 22\n",
            "Skipping line 223421: expected 15 fields, saw 22\n",
            "Skipping line 244032: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 270329: expected 15 fields, saw 22\n",
            "Skipping line 276484: expected 15 fields, saw 22\n",
            "Skipping line 304755: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 379449: expected 15 fields, saw 22\n",
            "Skipping line 386191: expected 15 fields, saw 22\n",
            "Skipping line 391811: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 414348: expected 15 fields, saw 22\n",
            "Skipping line 414773: expected 15 fields, saw 22\n",
            "Skipping line 417572: expected 15 fields, saw 22\n",
            "Skipping line 419496: expected 15 fields, saw 22\n",
            "Skipping line 430528: expected 15 fields, saw 22\n",
            "Skipping line 442230: expected 15 fields, saw 22\n",
            "Skipping line 450931: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 465377: expected 15 fields, saw 22\n",
            "Skipping line 467685: expected 15 fields, saw 22\n",
            "Skipping line 485055: expected 15 fields, saw 22\n",
            "Skipping line 487220: expected 15 fields, saw 22\n",
            "Skipping line 496076: expected 15 fields, saw 22\n",
            "Skipping line 512269: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 529505: expected 15 fields, saw 22\n",
            "Skipping line 531286: expected 15 fields, saw 22\n",
            "Skipping line 535424: expected 15 fields, saw 22\n",
            "Skipping line 569898: expected 15 fields, saw 22\n",
            "Skipping line 586293: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 593880: expected 15 fields, saw 22\n",
            "Skipping line 599274: expected 15 fields, saw 22\n",
            "Skipping line 607961: expected 15 fields, saw 22\n",
            "Skipping line 612413: expected 15 fields, saw 22\n",
            "Skipping line 615913: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 677580: expected 15 fields, saw 22\n",
            "Skipping line 687191: expected 15 fields, saw 22\n",
            "Skipping line 710819: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 728692: expected 15 fields, saw 22\n",
            "Skipping line 730216: expected 15 fields, saw 22\n",
            "Skipping line 758397: expected 15 fields, saw 22\n",
            "Skipping line 760061: expected 15 fields, saw 22\n",
            "Skipping line 768935: expected 15 fields, saw 22\n",
            "Skipping line 769483: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 822725: expected 15 fields, saw 22\n",
            "Skipping line 823621: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 857041: expected 15 fields, saw 22\n",
            "Skipping line 857320: expected 15 fields, saw 22\n",
            "Skipping line 858565: expected 15 fields, saw 22\n",
            "Skipping line 860629: expected 15 fields, saw 22\n",
            "Skipping line 864033: expected 15 fields, saw 22\n",
            "Skipping line 868673: expected 15 fields, saw 22\n",
            "Skipping line 869189: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 938605: expected 15 fields, saw 22\n",
            "Skipping line 940100: expected 15 fields, saw 22\n",
            "Skipping line 975137: expected 15 fields, saw 22\n",
            "Skipping line 976314: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 985597: expected 15 fields, saw 22\n",
            "Skipping line 990873: expected 15 fields, saw 22\n",
            "Skipping line 991806: expected 15 fields, saw 22\n",
            "Skipping line 1019808: expected 15 fields, saw 22\n",
            "Skipping line 1021526: expected 15 fields, saw 22\n",
            "Skipping line 1023905: expected 15 fields, saw 22\n",
            "Skipping line 1044207: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1084683: expected 15 fields, saw 22\n",
            "Skipping line 1093288: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1136430: expected 15 fields, saw 22\n",
            "Skipping line 1139815: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1179821: expected 15 fields, saw 22\n",
            "Skipping line 1195351: expected 15 fields, saw 22\n",
            "Skipping line 1202007: expected 15 fields, saw 22\n",
            "Skipping line 1224868: expected 15 fields, saw 22\n",
            "Skipping line 1232490: expected 15 fields, saw 22\n",
            "Skipping line 1238697: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1258654: expected 15 fields, saw 22\n",
            "Skipping line 1279948: expected 15 fields, saw 22\n",
            "Skipping line 1294360: expected 15 fields, saw 22\n",
            "Skipping line 1302240: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1413654: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1687095: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1805966: expected 15 fields, saw 22\n",
            "\n",
            "Skipping line 1892134: expected 15 fields, saw 22\n",
            "\n",
            "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\232109533.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n",
        "# Randomly selecting 100k reviews\n",
        "balanced_data = data.sample(n=100000, random_state=1)\n",
        "# Saving the sampled dataset to a new TSV file\n",
        "balanced_data.to_csv('sampled_dataset.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "998c6f49",
      "metadata": {
        "id": "998c6f49",
        "outputId": "b7fc5205-d510-40dd-9381-41a69f101c09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2640254, 15), (100000, 15))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape,balanced_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f9a3053",
      "metadata": {
        "id": "9f9a3053"
      },
      "source": [
        "# Reading balanced Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0bcc95a",
      "metadata": {
        "id": "b0bcc95a",
        "outputId": "dfa933be-50cb-44c3-c30a-9da5c8199ac5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\2756616047.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  balanced_data=pd.read_csv('sampled_dataset.tsv', sep='\\t', error_bad_lines=False)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>48006260</td>\n",
              "      <td>RTCLHUE5XW7AS</td>\n",
              "      <td>B0083J78GY</td>\n",
              "      <td>955804173</td>\n",
              "      <td>Canopy 2-Year Office Product Protection Plan</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Great</td>\n",
              "      <td>2015-02-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>15333704</td>\n",
              "      <td>RZHL9W1IW3NL9</td>\n",
              "      <td>B00DF9YOIC</td>\n",
              "      <td>473310322</td>\n",
              "      <td>Silver / Gold Blue Butterfly 2 Year 2017-18 &amp; ...</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>MUCH BETTER THAN I EXPECTED</td>\n",
              "      <td>The pocket calendar is better than I expected,...</td>\n",
              "      <td>2013-12-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>42986671</td>\n",
              "      <td>R910MA53M5SOX</td>\n",
              "      <td>B001QVXHR0</td>\n",
              "      <td>768255570</td>\n",
              "      <td>Printronic Remanufactured Ink Cartridge Replac...</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Ink</td>\n",
              "      <td>The cartridges are no good, because the ink do...</td>\n",
              "      <td>2013-04-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>48229683</td>\n",
              "      <td>R32SNFLPNU71V9</td>\n",
              "      <td>B00A73PCT4</td>\n",
              "      <td>161179273</td>\n",
              "      <td>2.4G Wireless Automatic USB Laser Handheld Bar...</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>bar code scanner not a good product</td>\n",
              "      <td>the scanner can not be set up for a carriage c...</td>\n",
              "      <td>2013-08-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>14820508</td>\n",
              "      <td>R2BE84Z6ZM4YX6</td>\n",
              "      <td>B00007BG8P</td>\n",
              "      <td>847877046</td>\n",
              "      <td>Sony SVM-75LS Ink and Paper Value Pack</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Clarity &amp; Speed</td>\n",
              "      <td>I have been using the Sony dye-sub printers fo...</td>\n",
              "      <td>2010-01-21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US     48006260   RTCLHUE5XW7AS  B0083J78GY       955804173   \n",
              "1          US     15333704   RZHL9W1IW3NL9  B00DF9YOIC       473310322   \n",
              "2          US     42986671   R910MA53M5SOX  B001QVXHR0       768255570   \n",
              "3          US     48229683  R32SNFLPNU71V9  B00A73PCT4       161179273   \n",
              "4          US     14820508  R2BE84Z6ZM4YX6  B00007BG8P       847877046   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0       Canopy 2-Year Office Product Protection Plan  Office Products   \n",
              "1  Silver / Gold Blue Butterfly 2 Year 2017-18 & ...  Office Products   \n",
              "2  Printronic Remanufactured Ink Cartridge Replac...  Office Products   \n",
              "3  2.4G Wireless Automatic USB Laser Handheld Bar...  Office Products   \n",
              "4             Sony SVM-75LS Ink and Paper Value Pack  Office Products   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
              "0          5.0            0.0          0.0    N                 Y   \n",
              "1          5.0            0.0          0.0    N                 Y   \n",
              "2          1.0            0.0          0.0    N                 Y   \n",
              "3          1.0            0.0          0.0    N                 Y   \n",
              "4          4.0            0.0          0.0    N                 Y   \n",
              "\n",
              "                       review_headline  \\\n",
              "0                           Five Stars   \n",
              "1          MUCH BETTER THAN I EXPECTED   \n",
              "2                                  Ink   \n",
              "3  bar code scanner not a good product   \n",
              "4                      Clarity & Speed   \n",
              "\n",
              "                                         review_body review_date  \n",
              "0                                              Great  2015-02-28  \n",
              "1  The pocket calendar is better than I expected,...  2013-12-14  \n",
              "2  The cartridges are no good, because the ink do...  2013-04-04  \n",
              "3  the scanner can not be set up for a carriage c...  2013-08-03  \n",
              "4  I have been using the Sony dye-sub printers fo...  2010-01-21  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "balanced_data=pd.read_csv('sampled_dataset.tsv', sep='\\t', error_bad_lines=False)\n",
        "balanced_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34cdd727",
      "metadata": {
        "id": "34cdd727"
      },
      "source": [
        "# Preparing the Dataset and Displaying the Initial Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "932c1172",
      "metadata": {
        "scrolled": true,
        "id": "932c1172",
        "outputId": "cd1eb83d-4b86-4ccf-e040-4f3e727a7cd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Five Stars Great</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MUCH BETTER THAN I EXPECTED The pocket calenda...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ink The cartridges are no good, because the in...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bar code scanner not a good product the scanne...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Clarity &amp; Speed I have been using the Sony dye...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Good I'm still trying to become fimilar with i...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Brother Compatible Cartridges Just installed c...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Five Stars Great markers!</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>One Star it only lasted for a few pages</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Great for Showcasing Your Marketing Pieces As ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Reviews  Ratings\n",
              "0                                   Five Stars Great      5.0\n",
              "1  MUCH BETTER THAN I EXPECTED The pocket calenda...      5.0\n",
              "2  Ink The cartridges are no good, because the in...      1.0\n",
              "3  bar code scanner not a good product the scanne...      1.0\n",
              "4  Clarity & Speed I have been using the Sony dye...      4.0\n",
              "5  Good I'm still trying to become fimilar with i...      3.0\n",
              "6  Brother Compatible Cartridges Just installed c...      5.0\n",
              "7                          Five Stars Great markers!      5.0\n",
              "8            One Star it only lasted for a few pages      1.0\n",
              "9  Great for Showcasing Your Marketing Pieces As ...      5.0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creating a new DataFrame with only 'Reviews' and 'Ratings' columns\n",
        "dataset = balanced_data[['review_headline', 'review_body', 'star_rating']].copy()\n",
        "#Concatenate 'review_headline' and 'review_body' to create a 'Reviews' column\n",
        "dataset['Reviews'] = dataset['review_headline'] + ' ' + dataset['review_body']\n",
        "#Renaming the star_rating column to Ratings\n",
        "dataset.rename(columns={'star_rating': 'Ratings'}, inplace=True)\n",
        "\n",
        "# Dropping the 'review_headline' and 'review_body' columns\n",
        "dataset.drop(['review_headline', 'review_body'], axis=1, inplace=True)\n",
        "dataset = dataset[['Reviews', 'Ratings']]\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dde1f5da",
      "metadata": {
        "id": "dde1f5da"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/Upwork/dataset.csv')\n",
        "dataset.drop(['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8a8be36d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8a8be36d",
        "outputId": "6d3a2250-515b-4758-9044-c269bfc678c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brother Compatible Cartridges Just installed cartridges - was worried as the shape seemed different.  Have had NO problems with the ink or printing thus far.  SO MUCH CHEAPER!!!! Do you make them for other printers?!!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset.Reviews[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4430977d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4430977d",
        "outputId": "765219cb-8c30-4b67-91a3-4b2d2184e370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews    6\n",
              "Ratings    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ca6800",
      "metadata": {
        "id": "53ca6800"
      },
      "source": [
        "# Dropping NAN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ce950c1d",
      "metadata": {
        "id": "ce950c1d"
      },
      "outputs": [],
      "source": [
        "dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3bf9a1e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf9a1e1",
        "outputId": "38653738-51b8-484a-a8f3-917acc85fad7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews    0\n",
              "Ratings    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd5e0bc8",
      "metadata": {
        "id": "dd5e0bc8"
      },
      "source": [
        "# Count of Reviews by Star Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "da4e41a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da4e41a8",
        "outputId": "87665694-d06d-4302-9eaf-2b84d61ca841"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    59848\n",
              "4.0    15775\n",
              "1.0    11830\n",
              "3.0     7287\n",
              "2.0     5254\n",
              "Name: Ratings, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset['Ratings'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8858a462",
      "metadata": {
        "id": "8858a462"
      },
      "source": [
        "# Classification of reviews by Stars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aa04b5fa",
      "metadata": {
        "id": "aa04b5fa"
      },
      "outputs": [],
      "source": [
        "positive_reviews = dataset[dataset['Ratings'].isin([4, 5])]\n",
        "negative_reviews = dataset[dataset['Ratings'].isin([1, 2])]\n",
        "neutral_reviews = dataset[dataset['Ratings'] == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a5389fa4",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5389fa4",
        "outputId": "b6053d54-4d70-4389-8651-2e117a61871f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive reviews\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews    75623\n",
              "Ratings    75623\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print('Number of positive reviews')\n",
        "positive_reviews.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9f3c1e76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f3c1e76",
        "outputId": "b35fc87e-57c1-4bc5-f65a-beafbdba1c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Negative reviews\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews    17084\n",
              "Ratings    17084\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print('Number of Negative reviews')\n",
        "negative_reviews.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "32e6d36a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32e6d36a",
        "outputId": "8bc8be95-588b-47e5-c40e-725ed6ca7c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Negative reviews\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews    7287\n",
              "Ratings    7287\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print('Number of Negative reviews')\n",
        "neutral_reviews.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e97022a",
      "metadata": {
        "id": "5e97022a"
      },
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dbb352c",
      "metadata": {
        "id": "7dbb352c"
      },
      "source": [
        "# word2vec-google-news-300"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0119c8",
      "metadata": {
        "id": "fb0119c8"
      },
      "source": [
        "The \"word2vec-google-news-300\" model is a popular and widely-used pre-trained Word2Vec model. It is trained on a large Google News dataset and provides 300-dimensional word vectors, making it a valuable resource for a wide range of NLP applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d0c54eb8",
      "metadata": {
        "scrolled": true,
        "id": "d0c54eb8"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "766f896f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "766f896f",
        "outputId": "f0e103b9-74b5-47f3-c930-636e973df6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "wv=api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "97c27308",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97c27308",
        "outputId": "ddb816c2-665f-44fb-ef76-dfd966e80767"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2240968"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "similarity=wv.similarity('cartridges', 'product')\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2a6af8fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a6af8fe",
        "outputId": "7a732516-0b0f-448f-8180-81a238c3815e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity between student and teacher is : 0.63013655\n"
          ]
        }
      ],
      "source": [
        "similarity=wv.similarity(w1='teacher',w2='student')\n",
        "print('similarity between student and teacher is :',similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a73f680d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a73f680d",
        "outputId": "0d15d410-3874-4670-8ac2-618aab2ea0b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mother', 0.8462507128715515)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "analogy_result=wv.most_similar(positive=['father', 'woman'], negative=['man'], topn=1)\n",
        "analogy_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "25a1070e",
      "metadata": {
        "id": "25a1070e"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Extracting the \"Reviews\" column\n",
        "reviews = dataset['Reviews']\n",
        "\n",
        "# Splitting the reviews into lists of words (no preprocessing)\n",
        "Reviews = [review.split() for review in reviews]\n",
        "\n",
        "# Training the Word2Vec model\n",
        "model = Word2Vec(Reviews, vector_size=300, window=13, min_count=9)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"reviews_word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b6f64f74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6f64f74",
        "outputId": "e5a5510f-dab7-4936-a55d-32c11821c82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity using custom Word2Vec model: 0.21525433659553528\n"
          ]
        }
      ],
      "source": [
        "similarity = model.wv.similarity('cartridges', 'product')\n",
        "\n",
        "print(f\"Similarity using custom Word2Vec model: {similarity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3d761081",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d761081",
        "outputId": "591e8a5b-ed1f-42f7-f59d-d2f2b4e1ad4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity using custom Word2Vec model: 0.11104869842529297\n"
          ]
        }
      ],
      "source": [
        "similarity = model.wv.similarity('excellent', 'product')\n",
        "\n",
        "print(f\"Similarity using custom Word2Vec model: {similarity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e5b426",
      "metadata": {
        "id": "03e5b426"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "76cad3b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76cad3b3",
        "outputId": "12bc5564-2beb-4d2b-f853-ad0d1ab702b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dell', 0.6989747285842896)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "analogy_result=model.wv.most_similar(positive=['brother','mother'],negative=['sister'],topn=1)\n",
        "analogy_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "637898b2",
      "metadata": {
        "id": "637898b2"
      },
      "source": [
        "# Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "927a4b88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "927a4b88",
        "outputId": "d617afb8-d12a-40b5-a2c5-97705026a786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy Result: [('quality,', 0.5170270800590515)]\n"
          ]
        }
      ],
      "source": [
        "analogy_result = model.wv.most_similar(positive=['Sony', 'quality'], negative=['best'], topn=1)\n",
        "print(\"Analogy Result:\", analogy_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c257bee",
      "metadata": {
        "id": "6c257bee"
      },
      "source": [
        "# Example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d1a82e18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1a82e18",
        "outputId": "710219a0-b444-4522-be0d-88603aa03e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy Result: [('printers,', 0.6918996572494507)]\n"
          ]
        }
      ],
      "source": [
        "analogy_result =model.wv.most_similar(positive=['Cartridges', 'printers'], negative=['product'], topn=1)\n",
        "print(\"Analogy Result:\", analogy_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57cb2169",
      "metadata": {
        "id": "57cb2169"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ba1750",
      "metadata": {
        "id": "85ba1750"
      },
      "source": [
        "In terms of encoding semantic similarities between words, the pretrained model (\"word2vec-google-news-300\") beats the custom-trained model. This is due to the pretrained model's utilization of a large and diverse dataset during training, which allows it to learn larger language connection and contexts, resulting in greater similarity scores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de2e72c",
      "metadata": {
        "id": "7de2e72c"
      },
      "source": [
        "# Simple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5ce5f1b4",
      "metadata": {
        "id": "5ce5f1b4"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the pre-trained Word2Vec model\n",
        "word2vec_model = Word2Vec.load(\"reviews_word2vec.model\")\n",
        "\n",
        "# Split your dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = dataset['Reviews']  # Extract the 'reviews' column as features\n",
        "y = dataset['Ratings']  # Extract the 'ratings' column as labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f34e4de1",
      "metadata": {
        "id": "f34e4de1"
      },
      "outputs": [],
      "source": [
        "# Calculating average Word2Vec vectors for each review in the dataset\n",
        "def calculate_average_word2vec(review, model):\n",
        "    words = review.split()  # Assuming each review is a space-separated string\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "        if word in model.wv:  # Check if the word is in the Word2Vec model's vocabulary\n",
        "            vectors.append(model.wv[word])\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3cec9dbc",
      "metadata": {
        "id": "3cec9dbc"
      },
      "outputs": [],
      "source": [
        "X_train_word2vec = np.array([calculate_average_word2vec(review, word2vec_model) for review in X_train])\n",
        "X_test_word2vec = np.array([calculate_average_word2vec(review, word2vec_model) for review in X_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "290dc42a",
      "metadata": {
        "id": "290dc42a"
      },
      "source": [
        "# Perceptron models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ab8cf4d5",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8cf4d5",
        "outputId": "0e8d6e9d-e9a0-47ce-a3db-a9eb215b2838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy with perceptron Model: 0.6779338966948347\n"
          ]
        }
      ],
      "source": [
        "# Training Perceptron models\n",
        "perceptron_word2vec = Perceptron()\n",
        "perceptron_word2vec.fit(X_train_word2vec, y_train)\n",
        "y_pred_word2vec = perceptron_word2vec.predict(X_test_word2vec)\n",
        "accuracy_word2vec = accuracy_score(y_test, y_pred_word2vec)\n",
        "print('accuracy with perceptron Model:',accuracy_word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "470f8e4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "470f8e4d",
        "outputId": "db7566b0-a06f-49f6-f94a-d149133eb3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Perceptron with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.67      0.57      0.62      2375\n",
            "         2.0       0.28      0.09      0.14      1081\n",
            "         3.0       0.35      0.25      0.29      1507\n",
            "         4.0       0.35      0.36      0.35      3087\n",
            "         5.0       0.79      0.89      0.84     11949\n",
            "\n",
            "    accuracy                           0.68     19999\n",
            "   macro avg       0.49      0.43      0.45     19999\n",
            "weighted avg       0.65      0.68      0.66     19999\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Classification report for Perceptron with Word2Vec\n",
        "print(\"Classification Report for Perceptron with Word2Vec:\")\n",
        "print(classification_report(y_test, y_pred_word2vec))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "511b3b94",
      "metadata": {
        "id": "511b3b94"
      },
      "source": [
        "# SVM models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "773409bd",
      "metadata": {
        "id": "773409bd"
      },
      "outputs": [],
      "source": [
        "# Training SVM models\n",
        "svm_word2vec = SVC(kernel='linear')\n",
        "svm_word2vec.fit(X_train_word2vec, y_train)\n",
        "y_pred_svm_word2vec = svm_word2vec.predict(X_test_word2vec)\n",
        "accuracy_svm_word2vec = accuracy_score(y_test, y_pred_svm_word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c0d3bd20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0d3bd20",
        "outputId": "f55af1f1-118e-45fb-c888-248b0e9d8ff6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71943597179859"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy_svm_word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ce25ca4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce25ca4e",
        "outputId": "36b845fc-85cb-4388-a62e-82c07bd1b229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for SVM with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.63      0.78      0.70      2375\n",
            "         2.0       0.42      0.10      0.16      1081\n",
            "         3.0       0.44      0.28      0.34      1507\n",
            "         4.0       0.74      0.15      0.25      3087\n",
            "         5.0       0.76      0.96      0.85     11949\n",
            "\n",
            "    accuracy                           0.72     19999\n",
            "   macro avg       0.60      0.46      0.46     19999\n",
            "weighted avg       0.70      0.72      0.66     19999\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report for SVM with Word2Vec\n",
        "print(\"Classification Report for SVM with Word2Vec:\")\n",
        "print(classification_report(y_test, y_pred_svm_word2vec))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c5e674c",
      "metadata": {
        "id": "7c5e674c"
      },
      "source": [
        "# TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "cb4eebfa",
      "metadata": {
        "id": "cb4eebfa"
      },
      "outputs": [],
      "source": [
        "# TF-IDF Feature Extraction\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f6552b20",
      "metadata": {
        "id": "f6552b20"
      },
      "outputs": [],
      "source": [
        "# Training Perceptron model with TF-IDF features\n",
        "perceptron_tfidf = Perceptron()\n",
        "perceptron_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_tfidf = perceptron_tfidf.predict(X_test_tfidf)\n",
        "accuracy_tfidf_perceptron = accuracy_score(y_test, y_pred_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ea0bd2e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea0bd2e1",
        "outputId": "bd796b7a-f162-4303-b457-4721d959913d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Perceptron with TF-IDF:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.64      0.69      0.66      2375\n",
            "         2.0       0.27      0.27      0.27      1081\n",
            "         3.0       0.32      0.38      0.35      1507\n",
            "         4.0       0.46      0.37      0.41      3087\n",
            "         5.0       0.84      0.85      0.85     11949\n",
            "\n",
            "    accuracy                           0.69     19999\n",
            "   macro avg       0.51      0.51      0.51     19999\n",
            "weighted avg       0.69      0.69      0.69     19999\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report for Perceptron with TF-IDF\n",
        "print(\"Classification Report for Perceptron with TF-IDF:\")\n",
        "print(classification_report(y_test, y_pred_tfidf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "cc658087",
      "metadata": {
        "id": "cc658087"
      },
      "outputs": [],
      "source": [
        "# Training SVM model with TF-IDF features\n",
        "svm_tfidf = SVC(kernel='linear')\n",
        "svm_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
        "accuracy_tfidf_svm = accuracy_score(y_test, y_pred_svm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "267638c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "267638c0",
        "outputId": "a0b825e0-efab-42b4-b3e8-3f3e63281985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for SVM with TF-IDF:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.69      0.81      0.75      2375\n",
            "         2.0       0.46      0.22      0.30      1081\n",
            "         3.0       0.51      0.36      0.42      1507\n",
            "         4.0       0.59      0.36      0.45      3087\n",
            "         5.0       0.83      0.95      0.88     11949\n",
            "\n",
            "    accuracy                           0.76     19999\n",
            "   macro avg       0.61      0.54      0.56     19999\n",
            "weighted avg       0.73      0.76      0.73     19999\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report for SVM with TF-IDF\n",
        "print(\"Classification Report for SVM with TF-IDF:\")\n",
        "print(classification_report(y_test, y_pred_svm_tfidf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68b5646",
      "metadata": {
        "id": "b68b5646"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "220a3c8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "220a3c8f",
        "outputId": "7d601f2c-c087-4fa8-bec3-f5f837f1838f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron Word2Vec Accuracy: 0.6779338966948347\n",
            "Perceptron TF-IDF Accuracy: 0.6912845642282114\n",
            "SVM Word2Vec Accuracy: 0.71943597179859\n",
            "SVM TF-IDF Accuracy: 0.7579878993949698\n"
          ]
        }
      ],
      "source": [
        "# Comparing performances\n",
        "print(\"Perceptron Word2Vec Accuracy:\", accuracy_word2vec)\n",
        "print(\"Perceptron TF-IDF Accuracy:\", accuracy_tfidf_perceptron)\n",
        "\n",
        "print(\"SVM Word2Vec Accuracy:\", accuracy_svm_word2vec)\n",
        "print(\"SVM TF-IDF Accuracy:\", accuracy_tfidf_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205835df",
      "metadata": {
        "id": "205835df"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5313f5b",
      "metadata": {
        "id": "f5313f5b"
      },
      "source": [
        "In summary, the results indicate that TF-IDF features coupled with the SVM model consistently outperform Word2Vec features in both Perceptron and SVM models. The SVM with TF-IDF achieves the highest accuracy, suggesting that this combination is the most effective for the classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7d425c",
      "metadata": {
        "id": "5d7d425c"
      },
      "source": [
        "## Feedforward Neural Networks (FNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4534a803",
      "metadata": {
        "id": "4534a803"
      },
      "source": [
        "A Feedforward Neural Network (FNN) is a fundamental type of artificial neural network where information flows unidirectionally, from the input layer through hidden layers (if any) to the output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf5fbe4",
      "metadata": {
        "id": "8bf5fbe4"
      },
      "source": [
        "## a) Average Word2Vec Vectors as Input Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "7f0313b7",
      "metadata": {
        "id": "7f0313b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the Feedforward Neural Network model\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(FFN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "19741faa",
      "metadata": {
        "id": "19741faa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert Word2Vec vectors to PyTorch tensors\n",
        "X_train_word2vec_tensor = torch.tensor(X_train_word2vec, dtype=torch.float32)\n",
        "X_test_word2vec_tensor = torch.tensor(X_test_word2vec, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values - 1, dtype=torch.long)  # Subtract 1 to start labels from 0\n",
        "y_test_tensor = torch.tensor(y_test.values - 1, dtype=torch.long)    # Subtract 1 to start labels from 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f4a541e2",
      "metadata": {
        "id": "f4a541e2"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and set hyperparameters\n",
        "input_size = 300  # Size of Word2Vec vectors\n",
        "hidden_size1 = 50\n",
        "hidden_size2 = 5\n",
        "output_size = 5  #  there are 5 classes\n",
        "model_avg = FFN(input_size, hidden_size1, hidden_size2, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_avg.parameters(), lr=0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "33b5f4fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33b5f4fc",
        "outputId": "7d4ca188-43f3-4d94-b477-614219112e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of FNN with average Word2Vec vectors: 15.44%\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_avg(X_train_word2vec_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_avg(X_test_word2vec_tensor)\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    ffn_accuracy_avg = accuracy_score(y_test.values, predicted)\n",
        "    print(\"Accuracy of FNN with average Word2Vec vectors: {:.2f}%\".format(ffn_accuracy_avg * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b96f2c9",
      "metadata": {
        "id": "8b96f2c9"
      },
      "source": [
        "## b) First 10 Word2Vec Vectors Concatenated as Input Features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ratings = dataset['Ratings']\n",
        "Ratings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8dfYQcMHbY_",
        "outputId": "e5ee930c-c817-481c-fe31-d9ab1c9b0da8"
      },
      "id": "C8dfYQcMHbY_",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        5.0\n",
              "1        5.0\n",
              "2        1.0\n",
              "3        1.0\n",
              "4        4.0\n",
              "        ... \n",
              "99995    5.0\n",
              "99996    5.0\n",
              "99997    3.0\n",
              "99998    5.0\n",
              "99999    5.0\n",
              "Name: Ratings, Length: 99994, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "5d85f25e",
      "metadata": {
        "id": "5d85f25e"
      },
      "outputs": [],
      "source": [
        "# Modify X_train_word2vec and X_test_word2vec to keep only the first 10 vectors for each review\n",
        "X_train_word2vec_first10 = np.array([review[:10] for review in X_train_word2vec])\n",
        "X_test_word2vec_first10 = np.array([review[:10] for review in X_test_word2vec])\n",
        "\n",
        "# Convert the modified Word2Vec vectors to PyTorch tensors\n",
        "X_train_word2vec_first10_tensor = torch.tensor(X_train_word2vec_first10, dtype=torch.float32)\n",
        "X_test_word2vec_first10_tensor = torch.tensor(X_test_word2vec_first10, dtype=torch.float32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_word2vec_first10_tensor.shape)\n",
        "print(X_test_word2vec_first10_tensor.shape)\n",
        "\n",
        "#X_train_word2vec_first10_tensor has a shape of torch.Size([79995, 10]), indicating 79,995 samples, each with 10 vectors.\n",
        "#X_test_word2vec_first10_tensor has a shape of torch.Size([19999, 10]), indicating 19,999 samples, each with 10 vectors."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbhVgi4xEFpw",
        "outputId": "4af197bd-5f9a-4566-a16d-73561f2015b0"
      },
      "id": "SbhVgi4xEFpw",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([79995, 10])\n",
            "torch.Size([19999, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify y_train to keep only the first 10 labels for each review\n",
        "y_train_first10 = y_train[:79995]\n",
        "y_test_first10 = y_test[:19999]\n",
        "\n",
        "# Convert the modified labels to PyTorch tensors\n",
        "y_train_first10_tensor = torch.tensor(y_train_first10.values - 1, dtype=torch.long)  # Subtract 1 to start labels from 0\n",
        "y_test_first10_tensor = torch.tensor(y_test_first10.values - 1, dtype=torch.long)  # Subtract 1 to start labels from 0\n"
      ],
      "metadata": {
        "id": "IMfT1eglGAzP"
      },
      "id": "IMfT1eglGAzP",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "6af4b197",
      "metadata": {
        "id": "6af4b197"
      },
      "outputs": [],
      "source": [
        "# Instantiate a new FFN model for this task with correct input size\n",
        "model_first10 = FFN(input_size=10, hidden_size1=50, hidden_size2=5, output_size=5)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "optimizer_first10 = optim.Adam(model_first10.parameters(), lr=0.001)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "num_classes = 5  # Number of classes in your classification task\n",
        "y_train_one_hot = F.one_hot(y_train_first10_tensor, num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "2tvsZGtpLEPq"
      },
      "id": "2tvsZGtpLEPq",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_first10.shape)\n",
        "print(y_train_one_hot.shape)\n",
        "print(y_train_first10_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9vuio8tK024",
        "outputId": "721f518b-c266-4ea7-c295-d522c7654b02"
      },
      "id": "g9vuio8tK024",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([79995, 5])\n",
            "torch.Size([79995, 5])\n",
            "torch.Size([79995])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dg7PFUjLDGM"
      },
      "id": "0dg7PFUjLDGM",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "bea58721",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bea58721",
        "outputId": "87a6fb64-bf61-4ee0-b873-8f892532509e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of FNN with first 10 Word2Vec vectors: 15.09%\n"
          ]
        }
      ],
      "source": [
        "# Training the model for the reduced dataset\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer_first10.zero_grad()\n",
        "    outputs_first10 = model_first10(X_train_word2vec_first10_tensor)\n",
        "    loss_first10 = criterion(outputs_first10, y_train_first10_tensor)  # Use the original class labels, not one-hot encoded vectors\n",
        "    loss_first10.backward()\n",
        "    optimizer_first10.step()\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    test_outputs_first10 = model_first10(X_test_word2vec_first10_tensor)\n",
        "    _, predicted_first10 = torch.max(test_outputs_first10, 1)\n",
        "    ffn_accuracy_first10 = accuracy_score(y_test_first10.values, predicted_first10)\n",
        "    print(\"Accuracy of FNN with first 10 Word2Vec vectors: {:.2f}%\".format(ffn_accuracy_first10 * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee291a2e",
      "metadata": {
        "id": "ee291a2e"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Both Feedforward Neural Network models, trained on average Word2Vec vectors and the first 10 vectors, exhibited low accuracy around 15%. To improve, focusing on data cleaning, expanding the dataset, experimenting with diverse model architectures, optimizing hyperparameters, and exploring advanced embeddings like BERT could significantly enhance predictive capabilities. Addressing these areas is crucial for building a more accurate and reliable model."
      ],
      "metadata": {
        "id": "HbetxIVtTlhG"
      },
      "id": "HbetxIVtTlhG"
    },
    {
      "cell_type": "markdown",
      "id": "3673e41e",
      "metadata": {
        "id": "3673e41e"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a67c6e8",
      "metadata": {
        "id": "3a67c6e8"
      },
      "source": [
        "## a) Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "c731d296",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c731d296",
        "outputId": "6e231ebc-71bd-486c-e59b-119325ce2c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Simple RNN: 8.17%\n"
          ]
        }
      ],
      "source": [
        "# Define the SimpleRNN model\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_out, _ = self.rnn(x)\n",
        "        # Extract the last time step's hidden state\n",
        "        last_hidden_state = rnn_out[:, -1, :]\n",
        "        # Use the last time step's hidden state for classification\n",
        "        output = self.fc(last_hidden_state)\n",
        "        return output\n",
        "# Convert the first 10 Word2Vec vectors to PyTorch tensors\n",
        "X_train_word2vec_first10_tensor = torch.tensor(X_train_word2vec_first10, dtype=torch.float32)\n",
        "X_test_word2vec_first10_tensor = torch.tensor(X_test_word2vec_first10, dtype=torch.float32)\n",
        "\n",
        "# Ensure that the input tensors have the correct shape [batch_size, seq_len, input_size]\n",
        "X_train_word2vec_first10_tensor = X_train_word2vec_first10_tensor.unsqueeze(1).expand(-1, 10, -1)\n",
        "X_test_word2vec_first10_tensor = X_test_word2vec_first10_tensor.unsqueeze(1).expand(-1, 10, -1)\n",
        "\n",
        "# Instantiate the SimpleRNN model\n",
        "rnn_model = SimpleRNN(input_size=10, hidden_size=10, output_size=5)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion_rnn = nn.CrossEntropyLoss()\n",
        "optimizer_rnn = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer_rnn.zero_grad()\n",
        "    rnn_outputs = rnn_model(X_train_word2vec_first10_tensor)\n",
        "    loss_rnn = criterion_rnn(rnn_outputs, y_train_tensor)\n",
        "    loss_rnn.backward()\n",
        "    optimizer_rnn.step()\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    test_rnn_outputs = rnn_model(X_test_word2vec_first10_tensor)\n",
        "    _, predicted_rnn = torch.max(test_rnn_outputs, 1)\n",
        "    rnn_accuracy = accuracy_score(y_test.values, predicted_rnn)\n",
        "    print(\"Accuracy of Simple RNN: {:.2f}%\".format(rnn_accuracy * 100))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LELoqIfIRJSN"
      },
      "id": "LELoqIfIRJSN",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8206dee",
      "metadata": {
        "id": "d8206dee"
      },
      "source": [
        "## b) Gated Recurrent Unit (GRU)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "eddd3958",
      "metadata": {
        "id": "eddd3958"
      },
      "outputs": [],
      "source": [
        "# Define the GRU model\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gru_out, _ = self.gru(x)\n",
        "        output = self.fc(gru_out[:, -1, :])  # Use the last time step's output for classification\n",
        "        return output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "22337983",
      "metadata": {
        "id": "22337983"
      },
      "outputs": [],
      "source": [
        "# Instantiate the GRU model\n",
        "gru_model = GRUModel(input_size=10, hidden_size=10, output_size=5)\n",
        "\n",
        "# Define loss function and optimizer for GRU\n",
        "optimizer_gru = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "1092d68e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1092d68e",
        "outputId": "f88a2987-7436-438c-cf9e-49dbd0ca391d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of GRU: 5.39%\n"
          ]
        }
      ],
      "source": [
        "# Training the GRU model\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer_gru.zero_grad()\n",
        "    gru_outputs = gru_model(X_train_word2vec_first10_tensor)\n",
        "    loss_gru = criterion(gru_outputs, y_train_tensor)\n",
        "    loss_gru.backward()\n",
        "    optimizer_gru.step()\n",
        "\n",
        "# Test the GRU model\n",
        "with torch.no_grad():\n",
        "    test_gru_outputs = gru_model(X_test_word2vec_first10_tensor)\n",
        "    _, predicted_gru = torch.max(test_gru_outputs, 1)\n",
        "    gru_accuracy = accuracy_score(y_test.values, predicted_gru)\n",
        "    print(\"Accuracy of GRU: {:.2f}%\".format(gru_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcafc377",
      "metadata": {
        "id": "bcafc377"
      },
      "source": [
        "## c) Long Short-Term Memory (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "f88c7350",
      "metadata": {
        "id": "f88c7350"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out[:, -1, :])  # Use the last time step's output for classification\n",
        "        return output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "d136c90b",
      "metadata": {
        "id": "d136c90b"
      },
      "outputs": [],
      "source": [
        "# Instantiate the LSTM model\n",
        "lstm_model = LSTMModel(input_size=10, hidden_size=10, output_size=5)\n",
        "\n",
        "# Define loss function and optimizer for LSTM\n",
        "optimizer_lstm = optim.Adam(lstm_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "e0b6f338",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0b6f338",
        "outputId": "ada954a2-5ee9-4499-82d4-edf0e81836b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of LSTM: 8.82%\n"
          ]
        }
      ],
      "source": [
        "# Training the LSTM model\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer_lstm.zero_grad()\n",
        "    lstm_outputs = lstm_model(X_train_word2vec_first10_tensor)\n",
        "    loss_lstm = criterion(lstm_outputs, y_train_tensor)\n",
        "    loss_lstm.backward()\n",
        "    optimizer_lstm.step()\n",
        "\n",
        "# Test the LSTM model\n",
        "with torch.no_grad():\n",
        "    test_lstm_outputs = lstm_model(X_test_word2vec_first10_tensor)\n",
        "    _, predicted_lstm = torch.max(test_lstm_outputs, 1)\n",
        "    lstm_accuracy = accuracy_score(y_test.values, predicted_lstm)\n",
        "    print(\"Accuracy of LSTM: {:.2f}%\".format(lstm_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58562aa1",
      "metadata": {
        "id": "58562aa1"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the evaluation of different recurrent neural network architectures, including Simple RNN, GRU, and LSTM, the obtained accuracies were 8.17%, 5.39%, and 8.82%, respectively. Despite these efforts, the results indicate a need for more sophisticated model architectures and hyperparameter tuning. Techniques like increasing network depth, experimenting with different activation functions, and adjusting dropout rates could enhance the models' performance. Additionally, integrating pre-trained embeddings and exploring transfer learning methods might provide valuable insights. Continuous iteration and exploration of advanced techniques are crucial to achieving higher accuracy and improving the models' overall predictive power in natural language processing tasks."
      ],
      "metadata": {
        "id": "KUQiFtlvUGrQ"
      },
      "id": "KUQiFtlvUGrQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb95a3d",
      "metadata": {
        "id": "0eb95a3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9287228",
      "metadata": {
        "id": "a9287228"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}