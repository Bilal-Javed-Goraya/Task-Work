{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcb1d6e",
   "metadata": {},
   "source": [
    "# Dataset Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a2b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcf6ac",
   "metadata": {},
   "source": [
    "# Let's load the original tsv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed07928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\232109533.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n",
      "Skipping line 20773: expected 15 fields, saw 22\n",
      "Skipping line 39834: expected 15 fields, saw 22\n",
      "Skipping line 52957: expected 15 fields, saw 22\n",
      "Skipping line 54540: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 80276: expected 15 fields, saw 22\n",
      "Skipping line 96168: expected 15 fields, saw 22\n",
      "Skipping line 96866: expected 15 fields, saw 22\n",
      "Skipping line 98175: expected 15 fields, saw 22\n",
      "Skipping line 112539: expected 15 fields, saw 22\n",
      "Skipping line 119377: expected 15 fields, saw 22\n",
      "Skipping line 120065: expected 15 fields, saw 22\n",
      "Skipping line 124703: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 134024: expected 15 fields, saw 22\n",
      "Skipping line 153938: expected 15 fields, saw 22\n",
      "Skipping line 156225: expected 15 fields, saw 22\n",
      "Skipping line 168603: expected 15 fields, saw 22\n",
      "Skipping line 187002: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 200397: expected 15 fields, saw 22\n",
      "Skipping line 203809: expected 15 fields, saw 22\n",
      "Skipping line 207680: expected 15 fields, saw 22\n",
      "Skipping line 223421: expected 15 fields, saw 22\n",
      "Skipping line 244032: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 270329: expected 15 fields, saw 22\n",
      "Skipping line 276484: expected 15 fields, saw 22\n",
      "Skipping line 304755: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 379449: expected 15 fields, saw 22\n",
      "Skipping line 386191: expected 15 fields, saw 22\n",
      "Skipping line 391811: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 414348: expected 15 fields, saw 22\n",
      "Skipping line 414773: expected 15 fields, saw 22\n",
      "Skipping line 417572: expected 15 fields, saw 22\n",
      "Skipping line 419496: expected 15 fields, saw 22\n",
      "Skipping line 430528: expected 15 fields, saw 22\n",
      "Skipping line 442230: expected 15 fields, saw 22\n",
      "Skipping line 450931: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 465377: expected 15 fields, saw 22\n",
      "Skipping line 467685: expected 15 fields, saw 22\n",
      "Skipping line 485055: expected 15 fields, saw 22\n",
      "Skipping line 487220: expected 15 fields, saw 22\n",
      "Skipping line 496076: expected 15 fields, saw 22\n",
      "Skipping line 512269: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 529505: expected 15 fields, saw 22\n",
      "Skipping line 531286: expected 15 fields, saw 22\n",
      "Skipping line 535424: expected 15 fields, saw 22\n",
      "Skipping line 569898: expected 15 fields, saw 22\n",
      "Skipping line 586293: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 593880: expected 15 fields, saw 22\n",
      "Skipping line 599274: expected 15 fields, saw 22\n",
      "Skipping line 607961: expected 15 fields, saw 22\n",
      "Skipping line 612413: expected 15 fields, saw 22\n",
      "Skipping line 615913: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 677580: expected 15 fields, saw 22\n",
      "Skipping line 687191: expected 15 fields, saw 22\n",
      "Skipping line 710819: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 728692: expected 15 fields, saw 22\n",
      "Skipping line 730216: expected 15 fields, saw 22\n",
      "Skipping line 758397: expected 15 fields, saw 22\n",
      "Skipping line 760061: expected 15 fields, saw 22\n",
      "Skipping line 768935: expected 15 fields, saw 22\n",
      "Skipping line 769483: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 822725: expected 15 fields, saw 22\n",
      "Skipping line 823621: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 857041: expected 15 fields, saw 22\n",
      "Skipping line 857320: expected 15 fields, saw 22\n",
      "Skipping line 858565: expected 15 fields, saw 22\n",
      "Skipping line 860629: expected 15 fields, saw 22\n",
      "Skipping line 864033: expected 15 fields, saw 22\n",
      "Skipping line 868673: expected 15 fields, saw 22\n",
      "Skipping line 869189: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 938605: expected 15 fields, saw 22\n",
      "Skipping line 940100: expected 15 fields, saw 22\n",
      "Skipping line 975137: expected 15 fields, saw 22\n",
      "Skipping line 976314: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 985597: expected 15 fields, saw 22\n",
      "Skipping line 990873: expected 15 fields, saw 22\n",
      "Skipping line 991806: expected 15 fields, saw 22\n",
      "Skipping line 1019808: expected 15 fields, saw 22\n",
      "Skipping line 1021526: expected 15 fields, saw 22\n",
      "Skipping line 1023905: expected 15 fields, saw 22\n",
      "Skipping line 1044207: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1084683: expected 15 fields, saw 22\n",
      "Skipping line 1093288: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1136430: expected 15 fields, saw 22\n",
      "Skipping line 1139815: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1179821: expected 15 fields, saw 22\n",
      "Skipping line 1195351: expected 15 fields, saw 22\n",
      "Skipping line 1202007: expected 15 fields, saw 22\n",
      "Skipping line 1224868: expected 15 fields, saw 22\n",
      "Skipping line 1232490: expected 15 fields, saw 22\n",
      "Skipping line 1238697: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1258654: expected 15 fields, saw 22\n",
      "Skipping line 1279948: expected 15 fields, saw 22\n",
      "Skipping line 1294360: expected 15 fields, saw 22\n",
      "Skipping line 1302240: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1413654: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1687095: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1805966: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1892134: expected 15 fields, saw 22\n",
      "\n",
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\232109533.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('reviews.tsv', sep='\\t', error_bad_lines=False)\n",
    "# Randomly selecting 100k reviews\n",
    "balanced_data = data.sample(n=100000, random_state=1)\n",
    "# Saving the sampled dataset to a new TSV file\n",
    "balanced_data.to_csv('sampled_dataset.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998c6f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2640254, 15), (100000, 15))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,balanced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a3053",
   "metadata": {},
   "source": [
    "# Reading balanced Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0bcc95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9692\\2756616047.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  balanced_data=pd.read_csv('sampled_dataset.tsv', sep='\\t', error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>48006260</td>\n",
       "      <td>RTCLHUE5XW7AS</td>\n",
       "      <td>B0083J78GY</td>\n",
       "      <td>955804173</td>\n",
       "      <td>Canopy 2-Year Office Product Protection Plan</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great</td>\n",
       "      <td>2015-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>15333704</td>\n",
       "      <td>RZHL9W1IW3NL9</td>\n",
       "      <td>B00DF9YOIC</td>\n",
       "      <td>473310322</td>\n",
       "      <td>Silver / Gold Blue Butterfly 2 Year 2017-18 &amp; ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>MUCH BETTER THAN I EXPECTED</td>\n",
       "      <td>The pocket calendar is better than I expected,...</td>\n",
       "      <td>2013-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>42986671</td>\n",
       "      <td>R910MA53M5SOX</td>\n",
       "      <td>B001QVXHR0</td>\n",
       "      <td>768255570</td>\n",
       "      <td>Printronic Remanufactured Ink Cartridge Replac...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Ink</td>\n",
       "      <td>The cartridges are no good, because the ink do...</td>\n",
       "      <td>2013-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>48229683</td>\n",
       "      <td>R32SNFLPNU71V9</td>\n",
       "      <td>B00A73PCT4</td>\n",
       "      <td>161179273</td>\n",
       "      <td>2.4G Wireless Automatic USB Laser Handheld Bar...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>bar code scanner not a good product</td>\n",
       "      <td>the scanner can not be set up for a carriage c...</td>\n",
       "      <td>2013-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>14820508</td>\n",
       "      <td>R2BE84Z6ZM4YX6</td>\n",
       "      <td>B00007BG8P</td>\n",
       "      <td>847877046</td>\n",
       "      <td>Sony SVM-75LS Ink and Paper Value Pack</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Clarity &amp; Speed</td>\n",
       "      <td>I have been using the Sony dye-sub printers fo...</td>\n",
       "      <td>2010-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     48006260   RTCLHUE5XW7AS  B0083J78GY       955804173   \n",
       "1          US     15333704   RZHL9W1IW3NL9  B00DF9YOIC       473310322   \n",
       "2          US     42986671   R910MA53M5SOX  B001QVXHR0       768255570   \n",
       "3          US     48229683  R32SNFLPNU71V9  B00A73PCT4       161179273   \n",
       "4          US     14820508  R2BE84Z6ZM4YX6  B00007BG8P       847877046   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0       Canopy 2-Year Office Product Protection Plan  Office Products   \n",
       "1  Silver / Gold Blue Butterfly 2 Year 2017-18 & ...  Office Products   \n",
       "2  Printronic Remanufactured Ink Cartridge Replac...  Office Products   \n",
       "3  2.4G Wireless Automatic USB Laser Handheld Bar...  Office Products   \n",
       "4             Sony SVM-75LS Ink and Paper Value Pack  Office Products   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          5.0            0.0          0.0    N                 Y   \n",
       "1          5.0            0.0          0.0    N                 Y   \n",
       "2          1.0            0.0          0.0    N                 Y   \n",
       "3          1.0            0.0          0.0    N                 Y   \n",
       "4          4.0            0.0          0.0    N                 Y   \n",
       "\n",
       "                       review_headline  \\\n",
       "0                           Five Stars   \n",
       "1          MUCH BETTER THAN I EXPECTED   \n",
       "2                                  Ink   \n",
       "3  bar code scanner not a good product   \n",
       "4                      Clarity & Speed   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                              Great  2015-02-28  \n",
       "1  The pocket calendar is better than I expected,...  2013-12-14  \n",
       "2  The cartridges are no good, because the ink do...  2013-04-04  \n",
       "3  the scanner can not be set up for a carriage c...  2013-08-03  \n",
       "4  I have been using the Sony dye-sub printers fo...  2010-01-21  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data=pd.read_csv('sampled_dataset.tsv', sep='\\t', error_bad_lines=False)\n",
    "balanced_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cdd727",
   "metadata": {},
   "source": [
    "# Preparing the Dataset and Displaying the Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932c1172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Five Stars Great</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUCH BETTER THAN I EXPECTED The pocket calenda...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ink The cartridges are no good, because the in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar code scanner not a good product the scanne...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clarity &amp; Speed I have been using the Sony dye...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good I'm still trying to become fimilar with i...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brother Compatible Cartridges Just installed c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Five Stars Great markers!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One Star it only lasted for a few pages</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great for Showcasing Your Marketing Pieces As ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Ratings\n",
       "0                                   Five Stars Great      5.0\n",
       "1  MUCH BETTER THAN I EXPECTED The pocket calenda...      5.0\n",
       "2  Ink The cartridges are no good, because the in...      1.0\n",
       "3  bar code scanner not a good product the scanne...      1.0\n",
       "4  Clarity & Speed I have been using the Sony dye...      4.0\n",
       "5  Good I'm still trying to become fimilar with i...      3.0\n",
       "6  Brother Compatible Cartridges Just installed c...      5.0\n",
       "7                          Five Stars Great markers!      5.0\n",
       "8            One Star it only lasted for a few pages      1.0\n",
       "9  Great for Showcasing Your Marketing Pieces As ...      5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new DataFrame with only 'Reviews' and 'Ratings' columns\n",
    "dataset = balanced_data[['review_headline', 'review_body', 'star_rating']].copy()\n",
    "#Concatenate 'review_headline' and 'review_body' to create a 'Reviews' column\n",
    "dataset['Reviews'] = dataset['review_headline'] + ' ' + dataset['review_body']\n",
    "#Renaming the star_rating column to Ratings\n",
    "dataset.rename(columns={'star_rating': 'Ratings'}, inplace=True)\n",
    "\n",
    "# Dropping the 'review_headline' and 'review_body' columns\n",
    "dataset.drop(['review_headline', 'review_body'], axis=1, inplace=True)\n",
    "dataset = dataset[['Reviews', 'Ratings']]\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8be36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother Compatible Cartridges Just installed cartridges - was worried as the shape seemed different.  Have had NO problems with the ink or printing thus far.  SO MUCH CHEAPER!!!! Do you make them for other printers?!!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Reviews[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4430977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviews    6\n",
       "Ratings    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca6800",
   "metadata": {},
   "source": [
    "# Dropping NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce950c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf9a1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviews    0\n",
       "Ratings    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e0bc8",
   "metadata": {},
   "source": [
    "# Count of Reviews by Star Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4e41a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    59848\n",
       "4.0    15775\n",
       "1.0    11830\n",
       "3.0     7287\n",
       "2.0     5254\n",
       "Name: Ratings, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Ratings'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858a462",
   "metadata": {},
   "source": [
    "# Classification of reviews by Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa04b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = dataset[dataset['Ratings'].isin([4, 5])]\n",
    "negative_reviews = dataset[dataset['Ratings'].isin([1, 2])]\n",
    "neutral_reviews = dataset[dataset['Ratings'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5389fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reviews    75623\n",
       "Ratings    75623\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of positive reviews')\n",
    "positive_reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f3c1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Negative reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reviews    17084\n",
       "Ratings    17084\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of Negative reviews')\n",
    "negative_reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e6d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Negative reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reviews    7287\n",
       "Ratings    7287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of Negative reviews')\n",
    "neutral_reviews.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97022a",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb352c",
   "metadata": {},
   "source": [
    "# word2vec-google-news-300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0119c8",
   "metadata": {},
   "source": [
    "The \"word2vec-google-news-300\" model is a popular and widely-used pre-trained Word2Vec model. It is trained on a large Google News dataset and provides 300-dimensional word vectors, making it a valuable resource for a wide range of NLP applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c54eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766f896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c27308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2240968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity=wv.similarity('cartridges', 'product')\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a6af8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between student and teacher is : 0.63013655\n"
     ]
    }
   ],
   "source": [
    "similarity=wv.similarity(w1='teacher',w2='student')\n",
    "print('similarity between student and teacher is :',similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73f680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.8462507128715515)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_result=wv.most_similar(positive=['father', 'woman'], negative=['man'], topn=1)\n",
    "analogy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25a1070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Extracting the \"Reviews\" column\n",
    "reviews = dataset['Reviews']\n",
    "\n",
    "# Splitting the reviews into lists of words (no preprocessing)\n",
    "Reviews = [review.split() for review in reviews]\n",
    "\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(Reviews, vector_size=300, window=13, min_count=9)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"reviews_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6f64f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity using custom Word2Vec model: 0.21505537629127502\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('cartridges', 'product')\n",
    "\n",
    "print(f\"Similarity using custom Word2Vec model: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d761081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity using custom Word2Vec model: 0.10678459703922272\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('excellent', 'product')\n",
    "\n",
    "print(f\"Similarity using custom Word2Vec model: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5b426",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76cad3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dell', 0.655776858329773)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_result=model.wv.most_similar(positive=['brother','mother'],negative=['sister'],topn=1)\n",
    "analogy_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637898b2",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "927a4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Result: [('quality.', 0.5182642936706543)]\n"
     ]
    }
   ],
   "source": [
    "analogy_result = model.wv.most_similar(positive=['Sony', 'quality'], negative=['best'], topn=1)\n",
    "print(\"Analogy Result:\", analogy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c257bee",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a82e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Result: [('carts', 0.6927616596221924)]\n"
     ]
    }
   ],
   "source": [
    "analogy_result =model.wv.most_similar(positive=['Cartridges', 'printers'], negative=['product'], topn=1)\n",
    "print(\"Analogy Result:\", analogy_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb2169",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba1750",
   "metadata": {},
   "source": [
    "In terms of encoding semantic similarities between words, the pretrained model (\"word2vec-google-news-300\") beats the custom-trained model. This is due to the pretrained model's utilization of a large and diverse dataset during training, which allows it to learn larger language connection and contexts, resulting in greater similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2e72c",
   "metadata": {},
   "source": [
    "# Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce5f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the pre-trained Word2Vec model\n",
    "word2vec_model = Word2Vec.load(\"reviews_word2vec.model\")\n",
    "\n",
    "# Split your dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset['Reviews']  # Extract the 'reviews' column as features\n",
    "y = dataset['Ratings']  # Extract the 'ratings' column as labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f34e4de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average Word2Vec vectors for each review in the dataset\n",
    "def calculate_average_word2vec(review, model):\n",
    "    words = review.split()  # Assuming each review is a space-separated string\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in model.wv:  # Check if the word is in the Word2Vec model's vocabulary\n",
    "            vectors.append(model.wv[word])\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cec9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = np.array([calculate_average_word2vec(review, word2vec_model) for review in X_train])\n",
    "X_test_word2vec = np.array([calculate_average_word2vec(review, word2vec_model) for review in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290dc42a",
   "metadata": {},
   "source": [
    "# Perceptron models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab8cf4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with perceptron Model: 0.6583829191459573\n"
     ]
    }
   ],
   "source": [
    "# Training Perceptron models\n",
    "perceptron_word2vec = Perceptron()\n",
    "perceptron_word2vec.fit(X_train_word2vec, y_train)\n",
    "y_pred_word2vec = perceptron_word2vec.predict(X_test_word2vec)\n",
    "accuracy_word2vec = accuracy_score(y_test, y_pred_word2vec)\n",
    "print('accuracy with perceptron Model:',accuracy_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "470f8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Perceptron with Word2Vec:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.77      0.39      0.52      2375\n",
      "         2.0       0.32      0.07      0.12      1081\n",
      "         3.0       0.49      0.10      0.16      1507\n",
      "         4.0       0.48      0.15      0.23      3087\n",
      "         5.0       0.67      0.96      0.79     11949\n",
      "\n",
      "    accuracy                           0.66     19999\n",
      "   macro avg       0.55      0.34      0.37     19999\n",
      "weighted avg       0.62      0.66      0.59     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Classification report for Perceptron with Word2Vec\n",
    "print(\"Classification Report for Perceptron with Word2Vec:\")\n",
    "print(classification_report(y_test, y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b3b94",
   "metadata": {},
   "source": [
    "# SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773409bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVM models\n",
    "svm_word2vec = SVC(kernel='linear')\n",
    "svm_word2vec.fit(X_train_word2vec, y_train)\n",
    "y_pred_svm_word2vec = svm_word2vec.predict(X_test_word2vec)\n",
    "accuracy_svm_word2vec = accuracy_score(y_test, y_pred_svm_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0d3bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201860093004651"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svm_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce25ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM with Word2Vec:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.78      0.70      2375\n",
      "         2.0       0.44      0.09      0.15      1081\n",
      "         3.0       0.46      0.29      0.36      1507\n",
      "         4.0       0.74      0.15      0.25      3087\n",
      "         5.0       0.76      0.97      0.85     11949\n",
      "\n",
      "    accuracy                           0.72     19999\n",
      "   macro avg       0.60      0.46      0.46     19999\n",
      "weighted avg       0.70      0.72      0.66     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for SVM with Word2Vec\n",
    "print(\"Classification Report for SVM with Word2Vec:\")\n",
    "print(classification_report(y_test, y_pred_svm_word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e674c",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb4eebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Feature Extraction\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6552b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Perceptron model with TF-IDF features\n",
    "perceptron_tfidf = Perceptron()\n",
    "perceptron_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = perceptron_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf_perceptron = accuracy_score(y_test, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea0bd2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Perceptron with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.69      0.66      2375\n",
      "         2.0       0.27      0.27      0.27      1081\n",
      "         3.0       0.32      0.38      0.35      1507\n",
      "         4.0       0.46      0.37      0.41      3087\n",
      "         5.0       0.84      0.85      0.85     11949\n",
      "\n",
      "    accuracy                           0.69     19999\n",
      "   macro avg       0.51      0.51      0.51     19999\n",
      "weighted avg       0.69      0.69      0.69     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Perceptron with TF-IDF\n",
    "print(\"Classification Report for Perceptron with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc658087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVM model with TF-IDF features\n",
    "svm_tfidf = SVC(kernel='linear')\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf_svm = accuracy_score(y_test, y_pred_svm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "267638c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.69      0.81      0.75      2375\n",
      "         2.0       0.46      0.22      0.30      1081\n",
      "         3.0       0.51      0.36      0.42      1507\n",
      "         4.0       0.59      0.36      0.45      3087\n",
      "         5.0       0.83      0.95      0.88     11949\n",
      "\n",
      "    accuracy                           0.76     19999\n",
      "   macro avg       0.61      0.54      0.56     19999\n",
      "weighted avg       0.73      0.76      0.73     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for SVM with TF-IDF\n",
    "print(\"Classification Report for SVM with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_svm_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b5646",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "220a3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Word2Vec Accuracy: 0.6583829191459573\n",
      "Perceptron TF-IDF Accuracy: 0.6912845642282114\n",
      "SVM Word2Vec Accuracy: 0.7201860093004651\n",
      "SVM TF-IDF Accuracy: 0.7579878993949698\n"
     ]
    }
   ],
   "source": [
    "# Comparing performances \n",
    "print(\"Perceptron Word2Vec Accuracy:\", accuracy_word2vec)\n",
    "print(\"Perceptron TF-IDF Accuracy:\", accuracy_tfidf_perceptron)\n",
    "\n",
    "print(\"SVM Word2Vec Accuracy:\", accuracy_svm_word2vec)\n",
    "print(\"SVM TF-IDF Accuracy:\", accuracy_tfidf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205835df",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5313f5b",
   "metadata": {},
   "source": [
    "In summary, the results indicate that TF-IDF features coupled with the SVM model consistently outperform Word2Vec features in both Perceptron and SVM models. The SVM with TF-IDF achieves the highest accuracy, suggesting that this combination is the most effective for the classification task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
